{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T09:23:52.153071Z",
     "start_time": "2024-04-15T09:23:51.666685Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 16\n",
      "Python-dotenv could not parse statement starting at line 17\n",
      "Python-dotenv could not parse statement starting at line 18\n",
      "Python-dotenv could not parse statement starting at line 24\n",
      "Python-dotenv could not parse statement starting at line 27\n",
      "Python-dotenv could not parse statement starting at line 28\n",
      "Python-dotenv could not parse statement starting at line 29\n",
      "Python-dotenv could not parse statement starting at line 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:24:52.639300Z",
     "start_time": "2024-04-15T09:24:52.636039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class Sentence(BaseModel):\n",
    "    \"\"\"Standard sentence \"\"\"\n",
    "    sentence: str = Field(..., description=\"The sentence\")\n",
    "    category: str = Field(..., description=\"The category of the sentence\")\n",
    "    \n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    \"\"\"Sentence structure correct and classification.\"\"\"\n",
    "    sentences: list[Sentence] = Field(..., description=\"List of sentences\")\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Sentences)"
   ],
   "id": "1d83420f7d1718dc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:24:57.248718Z",
     "start_time": "2024-04-15T09:24:57.243845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template_zero_shot = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "You are a language expert in Japanese and English.\n",
    "Your task is to process words in pre-existing sentences that have incorrect segmentation of word types, especially nouns that are not properly separated from other word types by spaces.\n",
    "You will be provided with the nouns and the instructions needed to carry out the task.\n",
    "Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"\"\"),\n",
    "        (\"user\", \"\"\"\n",
    "        あなたは優秀なSEMコンサルタントです。\n",
    "        以下の 2 つのアクションを実行しください。\n",
    "        ・アクション1：\n",
    "        KWを日本語として適切な単語の品詞単位で区切ってください。\n",
    "        ただし、次の条件を適用して書き直してください。\n",
    "        ①「ライフネット 生命」は「ライフネット生命」で1つの名詞と判断\n",
    "        ②「保険」は種別を含めて1つの名詞と判断\n",
    "        例）「死亡」と「保険」を分けず、「死亡保険」で1つの単語と判断\n",
    "        例）種別はがん(ガン、癌)、死亡、医療、入院、女性、定期、就業不能、認知症など\n",
    "        ③処理されたクエリはスペースで区切られるようにしてください\n",
    "        ・アクション2：\n",
    "        次の手順で指定したKWをカテゴリに分類してください。\n",
    "        ①下記優先度の高いカテゴリから順番に分類\n",
    "        -競合他社\n",
    "        例)ソニー、楽天、オリックス、メットライフ、SBI、アクサ、三井住友、アフラックなど\n",
    "        -がん保険\n",
    "        -死亡保険\n",
    "        -就業不能保険\n",
    "        -医療保険レディース\n",
    "        -医療保険\n",
    "        -ライフネット生命\n",
    "        ②①に分類できなかったものは下記に分類してください。\n",
    "        -「生命保険」\n",
    "    \n",
    "        Input sentences:\n",
    "        {input}\n",
    "        \"\"\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n"
   ],
   "id": "4898becd7cbf6d7d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:26:04.908097Z",
     "start_time": "2024-04-15T09:26:04.905402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"aflac 終身 保険\n",
    "ja ポイント\n",
    "ja 三重 中央 会\n",
    "がん 保険 定期 終身\n",
    "がん 保険 潰瘍 性 大腸 炎\n",
    "がんかかる 費用\n",
    "ゆとりある 生活費\n",
    "アイコープ\n",
    "イオンカードがん 保険 評判\n",
    "ライフネット 生命 ev\n",
    "介護 保険 値上げ\n",
    "仙台 市 青葉 区 心療 内科\n",
    "保険はこの5つから選びなさい\n",
    "保険 控除\n",
    "保険 適用 外の病気\n",
    "個人 損害 賠償 保険\n",
    "借金 返済 保険 解約\n",
    "傷病 手当 いつからもらえる\n",
    "入院 決まってから保険\n",
    "医療 保険 30歳 女性\"\"\"\n",
    "text = text.split(\"\\n\")\n",
    "sentences: str = []\n",
    "for i in text:\n",
    "    sentences.append(\"'\"+i+\"'\")\n"
   ],
   "id": "448202c5481c5f14",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:26:17.194568Z",
     "start_time": "2024-04-15T09:26:17.190810Z"
    }
   },
   "cell_type": "code",
   "source": "template_zero_shot.format_prompt(input=sentences).to_string()",
   "id": "d671d7010560bd8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: \\nYou are a language expert in Japanese and English.\\nYour task is to process words in pre-existing sentences that have incorrect segmentation of word types, especially nouns that are not properly separated from other word types by spaces.\\nYou will be provided with the nouns and the instructions needed to carry out the task.\\nAnswer the user query. Wrap the output in `json` tags\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Sentence structure correct and classification.\", \"properties\": {\"sentences\": {\"title\": \"Sentences\", \"description\": \"List of sentences\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Sentence\"}}}, \"required\": [\"sentences\"], \"definitions\": {\"Sentence\": {\"title\": \"Sentence\", \"description\": \"Standard sentence \", \"type\": \"object\", \"properties\": {\"sentence\": {\"title\": \"Sentence\", \"description\": \"The sentence\", \"type\": \"string\"}, \"category\": {\"title\": \"Category\", \"description\": \"The category of the sentence\", \"type\": \"string\"}}, \"required\": [\"sentence\", \"category\"]}}}\\n```\\nHuman: \\n        あなたは優秀なSEMコンサルタントです。\\n        以下の 2 つのアクションを実行しください。\\n        ・アクション1：\\n        KWを日本語として適切な単語の品詞単位で区切ってください。\\n        ただし、次の条件を適用して書き直してください。\\n        ①「ライフネット 生命」は「ライフネット生命」で1つの名詞と判断\\n        ②「保険」は種別を含めて1つの名詞と判断\\n        例）「死亡」と「保険」を分けず、「死亡保険」で1つの単語と判断\\n        例）種別はがん(ガン、癌)、死亡、医療、入院、女性、定期、就業不能、認知症など\\n        ③処理されたクエリはスペースで区切られるようにしてください\\n        ・アクション2：\\n        次の手順で指定したKWをカテゴリに分類してください。\\n        ①下記優先度の高いカテゴリから順番に分類\\n        -競合他社\\n        例)ソニー、楽天、オリックス、メットライフ、SBI、アクサ、三井住友、アフラックなど\\n        -がん保険\\n        -死亡保険\\n        -就業不能保険\\n        -医療保険レディース\\n        -医療保険\\n        -ライフネット生命\\n        ②①に分類できなかったものは下記に分類してください。\\n        -「生命保険」\\n    \\n        Input sentences:\\n        [\"\\'aflac 終身 保険\\'\", \"\\'ja ポイント\\'\", \"\\'ja 三重 中央 会\\'\", \"\\'がん 保険 定期 終身\\'\", \"\\'がん 保険 潰瘍 性 大腸 炎\\'\", \"\\'がんかかる 費用\\'\", \"\\'ゆとりある 生活費\\'\", \"\\'アイコープ\\'\", \"\\'イオンカードがん 保険 評判\\'\", \"\\'ライフネット 生命 ev\\'\", \"\\'介護 保険 値上げ\\'\", \"\\'仙台 市 青葉 区 心療 内科\\'\", \"\\'保険はこの5つから選びなさい\\'\", \"\\'保険 控除\\'\", \"\\'保険 適用 外の病気\\'\", \"\\'個人 損害 賠償 保険\\'\", \"\\'借金 返済 保険 解約\\'\", \"\\'傷病 手当 いつからもらえる\\'\", \"\\'入院 決まってから保険\\'\", \"\\'医療 保険 30歳 女性\\'\"]\\n        '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:31:03.122481Z",
     "start_time": "2024-04-15T09:31:03.080114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_models.azure_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"OPENAI_API_LLM_DEPLOY_NAME_4_8k\"),\n",
    "    openai_api_type=os.getenv(\"OPENAI_API_TYPE\"),\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY_4\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    temperature=0.,\n",
    "    # request_timeout=600,\n",
    "    streaming=True,\n",
    ")\n",
    "model = template_zero_shot | llm | parser\n"
   ],
   "id": "91c4345ae0403262",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:31:40.032517Z",
     "start_time": "2024-04-15T09:31:03.624416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "start = time.time()\n",
    "try:\n",
    "    with get_openai_callback() as cb:\n",
    "        results = model.invoke({\"input\": sentences})\n",
    "        token = cb\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "end = time.time()\n",
    "print(\"total_time\", end-start)\n"
   ],
   "id": "49b9ac5ba696692e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_time 36.40451097488403\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:31:58.731649Z",
     "start_time": "2024-04-15T09:31:58.728810Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "18f1f54b6191a6e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentences(sentences=[Sentence(sentence=\"'aflac 終身保険'\", category='競合他社'), Sentence(sentence=\"'ja ポイント'\", category='生命保険'), Sentence(sentence=\"'ja 三重 中央 会'\", category='生命保険'), Sentence(sentence=\"'がん保険 定期終身'\", category='がん保険'), Sentence(sentence=\"'がん保険 潰瘍性大腸炎'\", category='がん保険'), Sentence(sentence=\"'がんかかる 費用'\", category='がん保険'), Sentence(sentence=\"'ゆとりある 生活費'\", category='生命保険'), Sentence(sentence=\"'アイコープ'\", category='生命保険'), Sentence(sentence=\"'イオンカードがん保険 評判'\", category='がん保険'), Sentence(sentence=\"'ライフネット生命 ev'\", category='ライフネット生命'), Sentence(sentence=\"'介護保険 値上げ'\", category='生命保険'), Sentence(sentence=\"'仙台 市 青葉 区 心療 内科'\", category='生命保険'), Sentence(sentence=\"'保険はこの5つから選びなさい'\", category='生命保険'), Sentence(sentence=\"'保険 控除'\", category='生命保険'), Sentence(sentence=\"'保険 適用 外の病気'\", category='生命保険'), Sentence(sentence=\"'個人 損害賠償保険'\", category='生命保険'), Sentence(sentence=\"'借金 返済保険 解約'\", category='生命保険'), Sentence(sentence=\"'傷病 手当 いつからもらえる'\", category='生命保険'), Sentence(sentence=\"'入院決まってから保険'\", category='生命保険'), Sentence(sentence=\"'医療保険 30歳 女性'\", category='医療保険レディース')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T09:32:21.948969Z",
     "start_time": "2024-04-15T09:32:21.945799Z"
    }
   },
   "cell_type": "code",
   "source": "len(results.sentences)",
   "id": "40893e47c0ee86fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b89bdf73bc4cad40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
